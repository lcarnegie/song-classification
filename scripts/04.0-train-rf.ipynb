{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5354f750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47817, 26)\n",
      "genre_top\n",
      "Rock             14155\n",
      "Experimental     10544\n",
      "Electronic        9260\n",
      "Hip-Hop           3536\n",
      "Folk              2773\n",
      "Pop               2325\n",
      "Instrumental      2070\n",
      "International     1378\n",
      "Classical         1212\n",
      "Jazz               564\n",
      "Name: count, dtype: int64\n",
      "['track_id', 'title', 'artist_name', 'genre_top', 'mfcc_1', 'mfcc_2', 'mfcc_3', 'mfcc_4', 'mfcc_5', 'mfcc_6', 'mfcc_7', 'mfcc_8', 'mfcc_9', 'mfcc_10', 'mfcc_11', 'mfcc_12', 'mfcc_13', 'mfcc_14', 'mfcc_15', 'mfcc_16', 'centroid_mean', 'centroid_variance', 'rolloff_mean', 'rolloff_variance', 'zcr_mean', 'zcr_variance']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "os.chdir(\"C:\\\\Users\\\\lucac\\\\Documents\\\\GitHub\\\\song-cluster\")\n",
    "\n",
    "# Replace with the path to your full dataset\n",
    "df = pd.read_csv('data/analysis_data/classifier_data.csv')\n",
    "\n",
    "# Filter the dataset to include only the specified genres\n",
    "df = df[df['genre_top'].isin([\n",
    "    'Classical', 'Electronic', 'Experimental', 'Folk', \n",
    "    'Hip-Hop', 'Instrumental', 'International', 'Jazz', \n",
    "    'Pop', 'Rock'])]\n",
    "\n",
    "# Quick peek\n",
    "print(df.shape)           # e.g. (5000,  ? )\n",
    "print(df['genre_top'].value_counts())\n",
    "print(df.columns.tolist())  # should list your feature columns + 'genre'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41d81c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Features vs target\n",
    "X = df.drop(columns=['genre_top', 'track_id', 'title', 'artist_name'])\n",
    "y = df['genre_top']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1e6222b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Baseline model\u001b[39;00m\n\u001b[32m      7\u001b[39m baseline_rf = RandomForestClassifier(\n\u001b[32m      8\u001b[39m     random_state=\u001b[32m42\u001b[39m,\n\u001b[32m      9\u001b[39m     n_jobs=-\u001b[32m1\u001b[39m, \n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m     max_features=\u001b[33m'\u001b[39m\u001b[33msqrt\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     15\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43mbaseline_rf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucac\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucac\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:487\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    476\u001b[39m trees = [\n\u001b[32m    477\u001b[39m     \u001b[38;5;28mself\u001b[39m._make_estimator(append=\u001b[38;5;28;01mFalse\u001b[39;00m, random_state=random_state)\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[32m    479\u001b[39m ]\n\u001b[32m    481\u001b[39m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[32m    484\u001b[39m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[32m    485\u001b[39m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[32m    486\u001b[39m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m trees = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthreads\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[32m    509\u001b[39m \u001b[38;5;28mself\u001b[39m.estimators_.extend(trees)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucac\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucac\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2001\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2002\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2003\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2004\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2005\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2007\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucac\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1649\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1650\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucac\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs) == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1760\u001b[39m     (\u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(\n\u001b[32m   1761\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING)):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1763\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1765\u001b[39m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[32m   1766\u001b[39m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[32m   1767\u001b[39m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Train the Random Forest using the default parameters and all features \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Baseline model\n",
    "baseline_rf = RandomForestClassifier(\n",
    "    random_state=42,\n",
    "    n_jobs=-1, \n",
    "    class_weight='balanced', # to handle class imbalance\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features='sqrt',\n",
    ")\n",
    "\n",
    "baseline_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3317b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "y_pred = baseline_rf.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Baseline Random Forest Classifier\")\n",
    "print(\"===================================\")\n",
    "print(\"Number of classes:\", len(baseline_rf.classes_))\n",
    "print(\"Classes:\", baseline_rf.classes_)\n",
    "print(\"Number of trees:\", baseline_rf.n_estimators)\n",
    "print(\"Max depth:\", baseline_rf.max_depth)\n",
    "print(\"Min samples split:\", baseline_rf.min_samples_split)\n",
    "print(\"Min samples leaf:\", baseline_rf.min_samples_leaf)\n",
    "print(\"Max features:\", baseline_rf.max_features)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "print(\"Feature importances:\")\n",
    "importances = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': baseline_rf.feature_importances_\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "print(importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2fcaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with top 10 features: 0.5533249686323714\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Classical      0.720     0.595     0.652       242\n",
      "   Electronic      0.518     0.607     0.559      1852\n",
      " Experimental      0.476     0.612     0.535      2109\n",
      "         Folk      0.494     0.310     0.381       555\n",
      "      Hip-Hop      0.542     0.321     0.403       707\n",
      " Instrumental      0.584     0.126     0.207       414\n",
      "International      0.758     0.181     0.292       276\n",
      "         Jazz      1.000     0.027     0.052       113\n",
      "          Pop      0.556     0.022     0.041       465\n",
      "         Rock      0.627     0.784     0.697      2831\n",
      "\n",
      "     accuracy                          0.553      9564\n",
      "    macro avg      0.627     0.358     0.382      9564\n",
      " weighted avg      0.564     0.553     0.521      9564\n",
      "\n",
      "Feature importances with top 15 features:\n",
      "              feature  importance\n",
      "0              mfcc_1    0.086261\n",
      "1              mfcc_4    0.073371\n",
      "7             mfcc_16    0.070314\n",
      "3              mfcc_6    0.069196\n",
      "2              mfcc_3    0.067316\n",
      "9             mfcc_10    0.066975\n",
      "4        rolloff_mean    0.066794\n",
      "5              mfcc_2    0.064304\n",
      "8        zcr_variance    0.063926\n",
      "6   centroid_variance    0.063508\n",
      "11             mfcc_5    0.063254\n",
      "12             mfcc_7    0.062379\n",
      "10      centroid_mean    0.061965\n",
      "13           zcr_mean    0.061641\n",
      "14   rolloff_variance    0.058796\n"
     ]
    }
   ],
   "source": [
    "# Re train the Random Forest using the default parameters and only the top 15 features\n",
    "top_15_features = importances.head(15)['feature'].tolist()\n",
    "X_train_top_15 = X_train[top_15_features]\n",
    "X_test_top_15 = X_test[top_15_features]\n",
    "\n",
    "# Train the model with only the top 10 features\n",
    "rf_top_15 = RandomForestClassifier(\n",
    "    random_state=42,\n",
    "    n_jobs=-1, \n",
    "    class_weight='balanced',\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features='sqrt',\n",
    ")\n",
    "\n",
    "rf_top_15.fit(X_train_top_15, y_train)\n",
    "\n",
    "# Evaluation\n",
    "y_pred_top_15 = rf_top_15.predict(X_test_top_15)\n",
    "print(\"Accuracy with top 10 features:\", accuracy_score(y_test, y_pred_top_15))\n",
    "print(classification_report(y_test, y_pred_top_15, digits=3))\n",
    "print(\"Feature importances with top 15 features:\")\n",
    "importances_top_15 = pd.DataFrame({\n",
    "    'feature': top_15_features,\n",
    "    'importance': rf_top_15.feature_importances_\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "print(importances_top_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84ce1db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/baseline_rf.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save baseline model for later use\n",
    "import joblib\n",
    "\n",
    "joblib.dump(baseline_rf, 'models/baseline_rf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20a003b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Tree Information:\n",
      "========================\n",
      "Number of nodes: 22023\n",
      "Max depth: 32\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "# Load the saved model\n",
    "loaded_rf = joblib.load('models/baseline_rf.pkl')\n",
    "\n",
    "# Get information about the final tree\n",
    "final_tree = loaded_rf.estimators_[-1]  # Access the last tree in the forest\n",
    "print(\"Final Tree Information:\")\n",
    "print(\"========================\")\n",
    "print(\"Number of nodes:\", final_tree.tree_.node_count)\n",
    "print(\"Max depth:\", final_tree.tree_.max_depth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
