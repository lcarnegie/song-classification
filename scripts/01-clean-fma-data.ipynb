{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c3a1c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PREAMBLE ##\n",
    "# Author: Luca Carnegie\n",
    "# Date: 2025-04-21\n",
    "\n",
    "# This code cleans the raw FMA metadata and puts it in a usable format for classifier training\n",
    "# as implemented in 3\n",
    "\n",
    "# Prerequisites: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a3bad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Change working directory to the repo\n",
    "os.chdir(\"C:\\\\Users\\\\lucac\\\\Documents\\\\GitHub\\\\song-cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75418a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre_top\n",
      "Rock             14155\n",
      "Experimental     10544\n",
      "Electronic        9260\n",
      "Hip-Hop           3536\n",
      "Folk              2773\n",
      "Pop               2325\n",
      "Instrumental      2070\n",
      "International     1378\n",
      "Classical         1212\n",
      "Jazz               564\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1. Load raw features with a 3-level header, skip the lone track_id row\n",
    "features = pd.read_csv(\n",
    "    'data/raw_data/fma_metadata/features.csv',\n",
    "    header=[0,1,2],\n",
    "    skiprows=[3]\n",
    ")\n",
    "\n",
    "# 2. Build a fresh DataFrame\n",
    "features_clean = pd.DataFrame()\n",
    "features_clean['track_id'] = features.iloc[:, 0]\n",
    "\n",
    "# 2b. MFCC means 1â€“16\n",
    "for i in range(1, 17):\n",
    "    mfcc_col = next(\n",
    "        col for col in features.columns\n",
    "        if col[0].startswith('mfcc') and col[1]=='mean' and int(col[2])==i\n",
    "    )\n",
    "    features_clean[f'mfcc_{i}'] = features[mfcc_col]\n",
    "\n",
    "# 2c. Centroid mean & variance\n",
    "cent_mean_col = next(c for c in features.columns if c[0].startswith('spectral_centroid') and c[1]=='mean')\n",
    "cent_std_col  = next(c for c in features.columns if c[0].startswith('spectral_centroid') and c[1]=='std')\n",
    "features_clean['centroid_mean']     = features[cent_mean_col]\n",
    "features_clean['centroid_variance'] = features[cent_std_col] ** 2\n",
    "\n",
    "# 2d. Rolloff mean & variance\n",
    "roll_mean_col = next(c for c in features.columns if c[0].startswith('spectral_rolloff') and c[1]=='mean')\n",
    "roll_std_col  = next(c for c in features.columns if c[0].startswith('spectral_rolloff') and c[1]=='std')\n",
    "features_clean['rolloff_mean']     = features[roll_mean_col]\n",
    "features_clean['rolloff_variance'] = features[roll_std_col] ** 2\n",
    "\n",
    "# 2e. ZCR mean & variance\n",
    "zcr_mean_col = next(c for c in features.columns if c[0].startswith('zcr') and c[1]=='mean')\n",
    "zcr_std_col  = next(c for c in features.columns if c[0].startswith('zcr') and c[1]=='std')\n",
    "features_clean['zcr_mean']      = features[zcr_mean_col]\n",
    "features_clean['zcr_variance']  = features[zcr_std_col] ** 2\n",
    "\n",
    "\n",
    "# 3. Load tracks metadata (2-level header, skip the track_id row)\n",
    "tracks = pd.read_csv(\n",
    "    'data/raw_data/fma_metadata/tracks.csv',\n",
    "    header=[0,1],\n",
    "    skiprows=[2]\n",
    ")\n",
    "\n",
    "# 4. Dynamically find the right MultiIndex keys\n",
    "track_id_col = tracks.columns[0]\n",
    "title_col    = next(col for col in tracks.columns if col[1] == 'title')\n",
    "artist_col   = next(col for col in tracks.columns if col[1] == 'name')\n",
    "genre_col    = next(col for col in tracks.columns if col[1] == 'genre_top')\n",
    "\n",
    "# 5. Build tracks_clean\n",
    "tracks_clean = pd.DataFrame({\n",
    "    'track_id':    tracks[track_id_col],\n",
    "    'title':       tracks[title_col],\n",
    "    'artist_name': tracks[artist_col],\n",
    "    'genre_top':   tracks[genre_col],\n",
    "})\n",
    "\n",
    "# 6. Merge & drop rows missing genre label\n",
    "merged = (\n",
    "    pd.merge(tracks_clean, features_clean, on='track_id', how='inner')\n",
    "      .dropna(subset=['genre_top'])\n",
    ")\n",
    "\n",
    "# 6.5 Drop any rows with missing values in the features\n",
    "merged = merged.dropna()\n",
    "\n",
    "merged.to_csv('data/analysis_data/classifier_data.csv', index=False)\n",
    "\n",
    "# 7. Limit genres to 10 and discard the rest\n",
    "merged['genre_top'] = merged['genre_top'].where(\n",
    "    merged['genre_top'].isin(merged['genre_top'].value_counts().nlargest(10).index),\n",
    "    'other'\n",
    ")\n",
    "\n",
    "# 8. Drop rows with 'other' genre\n",
    "merged = merged[merged['genre_top'] != 'other']\n",
    "\n",
    "# get counts of each genre\n",
    "genre_counts = merged['genre_top'].value_counts()\n",
    "print(genre_counts)\n",
    "\n",
    "\n",
    "# save the cleaned data\n",
    "merged.to_csv('data/analysis_data/classifier_data_top10.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e1967c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows without a value in tracks:  56977\n",
      "Number of rows in tracks dataframe:  106576\n",
      "Number of analysable rows in tracks dataframe:  49599\n"
     ]
    }
   ],
   "source": [
    "# how many rows don't have a value in genre_top in in tracks.csv? \n",
    "no_genre_songs = tracks[tracks['track.7'].isna()].shape[0]\n",
    "print(\"Number of rows without a value in tracks: \", no_genre_songs)\n",
    "\n",
    "# how many rows are there in the tracks dataframe?\n",
    "number_of_rows = tracks.shape[0]\n",
    "print(\"Number of rows in tracks dataframe: \", number_of_rows)\n",
    "\n",
    "# how many analysable rows are there, total (i.e. have a genre [all features] were extracted)\n",
    "print(\"Number of analysable rows in tracks dataframe: \", number_of_rows - no_genre_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e7ff4c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49596, 26)\n"
     ]
    }
   ],
   "source": [
    "# print the full dataframe, with all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "test_tracks = pd.read_csv(\"data/analysis_data/classifier_data.csv\", header=[0,1], skiprows=[2])\n",
    "\n",
    "# Print the first 5 rows of the tracks dataframe\n",
    "print(test_tracks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac73b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get me the first ten rows of features.csv and genres.csv and export them as a csv\n",
    "\n",
    "os.chdir(\"C:\\\\Users\\\\lucac\\\\Documents\\\\GitHub\\\\song-cluster\")\n",
    "\n",
    "features.head(10).to_csv(\"data/raw_data/features_head.csv\", index=False)\n",
    "tracks.head(10).to_csv(\"data/raw_data/tracks_head.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
